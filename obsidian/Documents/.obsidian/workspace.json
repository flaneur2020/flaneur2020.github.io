{
  "main": {
    "id": "1174348dbfdc2ac1",
    "type": "split",
    "children": [
      {
        "id": "cd9b3e6a5fc9db78",
        "type": "tabs",
        "children": [
          {
            "id": "26b8440cd4c98ca5",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "2024-01/CUDA Optimization - Part 1.md",
                "mode": "source",
                "source": false
              }
            }
          }
        ]
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "3fb298e53dc2e5e3",
    "type": "split",
    "children": [
      {
        "id": "079d5f1af574e4e8",
        "type": "tabs",
        "children": [
          {
            "id": "c6f7ac1787e42da5",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "byModifiedTimeReverse"
              }
            }
          },
          {
            "id": "0d3089e6530a8a76",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "tag:#GPU",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              }
            }
          },
          {
            "id": "007f1167cad12df1",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {}
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 341.5
  },
  "right": {
    "id": "0b9cf38bf3932929",
    "type": "split",
    "children": [
      {
        "id": "2dba8a398f6149da",
        "type": "tabs",
        "children": [
          {
            "id": "e5e3d61d732f7413",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "file": "2024-01/CUDA Optimization - Part 1.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "b93aed57f8f6452d",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "2024-01/CUDA Optimization - Part 1.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              }
            }
          },
          {
            "id": "413afa1cff3181ea",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {
                "file": "2024-01/CUDA Optimization - Part 1.md"
              }
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "command-palette:Open command palette": false,
      "markdown-importer:Open format converter": true,
      "canvas:Create new canvas": false,
      "obsidian-excalidraw-plugin:Create new drawing": false,
      "daily-notes:Open today's daily note": true,
      "publish:Publish changes...": false,
      "templates:Insert template": false
    }
  },
  "active": "26b8440cd4c98ca5",
  "lastOpenFiles": [
    "2024-01/LoRA From Scratch – Implement Low-Rank Adaptation for LLMs in PyTorch.md",
    "2024-01/assets/Pasted image 20240129152450.png",
    "2024-01/assets/Pasted image 20240129152257.png",
    "Home.md",
    "2024-01/CUDA Optimization - Part 1.md",
    "2024-01/AWQ - Activation-aware Weight Quantization for LLM Compression and Acceleration.md",
    "2024-01/Efficient LLM inference solution on Intel GPU.md",
    "2024-01/The case for 4-bit precision - k-bit Inference Scaling Laws.md",
    "2024-01/Understanding and Overcoming the Challenges of Efficient Transformer Quantization.md",
    "2023/2023-08/Books/学生为什么不喜欢学习.md",
    "2023/2023 - Index.md",
    "2024-01/MotherDuck - DuckDB in the cloud and in the client.md",
    "2024-01/CUDA Optimization - Part 2.md",
    "2024-01/Understanding Activation-Aware Weight Quantization (AWQ) - Boosting Inference Serving Efficiency in LLMs.md",
    "Nvidia CUDA Core-LaLM Decoding Attention Inference Optimization.md",
    "2024-01/From slow to SIMD - A Go optimization story.md",
    "2024-01/The Illustrated Stable Diffusion.md",
    "2024-01/LLM Decoding Attention-KV Cache Int8 Quantization.md",
    "2024-01/Nvidia CUDA Core-LLM Decoding Attention Inference Optimization.md",
    "2024-01/Towards Efficient Generative Large Language Model Serving - A Survey from Algorithms to Systems.md",
    "2024-01/Towards 100x Speedup - Full Stack Transformer Inference Optimization.md",
    "2024-01/10 Things Software Developers Should Learn about Learning.md",
    "2024-01/From idea to validation in 24 hours.md",
    "2024-01/assets/Pasted image 20240114120846.png",
    "2023/2023-11/FP8 versus INT8 for efficient deep learning inference.md",
    "2024-01/assets/Pasted image 20240111115835.png",
    "2024-01/assets/Pasted image 20240111115529.png",
    "2024-01/assets/Pasted image 20240110130317.png",
    "2024-01/assets/Pasted image 20240110130240.png",
    "2024-01/assets/Pasted image 20240110130025.png",
    "2024-01/assets/Pasted image 20240110125736.png",
    "2024-01/assets/Pasted image 20240110125425.png",
    "2024-01/assets",
    "2024-01/TokenAttention.md",
    "2024-01/inference-tutorial(001) - 深度学习基础.md",
    "2024/2024-01.md",
    "Untitled",
    "2024-01",
    "2023",
    "2023/2023-12/assets",
    "2023/2023-12",
    "2019/2019-02",
    "2019",
    "Untitled.canvas",
    "2023/2023-11/assets",
    "2023/2023-11"
  ]
}
---
layout: post
title: "[WIP] Math on VAE"
---

上篇 blog 中过了一下 VAE 的 intuition，还是很直白的，不过看介绍 VAE 背后的数学的文章总是觉得有点缺少连接感，看了两个星期总算在公式层面推通了一把，感觉对我这种数学基础不好的来讲还挺吃力，在这里记录一下当作备忘。

## 前置准备

在推公式之前，先把用到的数学公式复习/预习一下，后面就直接套进去就好。

### 概率的期望

可以用抽奖的例子来快速回忆起来概率的“期望”的概念：假如参加抽奖活动有一等奖和二等奖两种奖项，一等奖的概率是 1%，奖金 10000，二等奖的概率是 10%，奖金 100，问我参加这个抽奖活动可以赢得的奖金的期望是多少？

$$
\mathbb{E}[x] = \sum_{i=1}^{n} x_i p_i(x_i)
$$

其中 $x$ 是随机变量，$x_i$ 是随机变量的取值，$p_i(x_i)$ 是取值 $x_i$ 的概率。在这个例子中，我们抽奖得到奖金的期望是 $10000 \times 0.01 + 100 \times 0.1 = 110$。

对于连续的随机变量，期望的计算就是：

$$
\mathbb{E}[x] = \int x p(x) dx
$$

期望也可以通过采样的方法来估计，比如我们有一个样本集合 $X = \{x_1, x_2, \ldots, x_n\}$，那么期望可以这样估算：

$$
\mathbb{E}[x] \approx \frac{1}{n} \sum_{i=1}^{n} x_i, \,\,\,\, x_i \sim p(x)
$$

在机器学习中，我们手里有的是训练数据集，可以通过这组数据集作为样本集合来估算出期望的值。在推导公式的时候，我们可以将积分计算的期望替换成采样计算的期望，再代入训练数据估算的期望。

期望的计算也可以代入到函数中：

$$
\begin{align*}
\mathbb{E}[f(x)] &= \int f(x) p(x) dx \\
&\approx \frac{1}{n} \sum_{i=1}^{n} f(x_i), \,\,\,\, x_i \sim p(x)
\end{align*}
$$

### KL 散度

KL 散度是用来衡量两个概率分布之间的差异的，定义如下：

$$
\text{KL}(p||q) = \int p(x) \log \frac{p(x)}{q(x)} dx
$$

KL 散度有一个性质就是总是大于零，当且仅当 $p(x) = q(x)$ 时 KL 散度等于零。

根据苏神的博客里的说法，KL 散度也并非衡量两个概率分布的唯一办法，但是 KL 散度可以写成期望的形式，这在 VAE 的推导里面会用到。

## 图片生成模型

在 VAE 中，我们希望通过一个神经网络来生成图片，这个神经网络的输入是一个随机变量 $z$，输出是图片 $x$。

$p(x)$ 的概率分布就是我们希望生成的图片的分布。怎样理解这个概率分布？我们可以把 $x$ 对应一组 128x128 个像素组成的向量，对于一张有效的图片（比如猫狗照片），$p(x)$ 会接近 1，对于一张无效的乱码图片，$p(x)$ 会接近于 0。

$x$ 作为一个随机变量，大部分采样的值按说都是无效的，我们希望通过神经网络生成有效的图片，使 $p(x)$ 都尽可能的接近 1。